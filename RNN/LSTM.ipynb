{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c06e9ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "01863407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text document of Jane Eyre, by Charlotte Brontë\n",
    "response = requests.get(\"https://www.gutenberg.org/files/1260/1260-0.txt\")\n",
    "soup_doc = BeautifulSoup(response.content, \"html.parser\")\n",
    "raw_string_data = soup_doc.text\n",
    "vocabulary = sorted(set(raw_string_data))\n",
    "\n",
    "# Creating maps from character values to numerical representations\n",
    "string2index = {s:i for i, s in enumerate(vocabulary)}\n",
    "index2string = np.array(vocabulary)\n",
    "\n",
    "def vectorize_string(raw_string):\n",
    "    return np.array([string2index[s] for s in raw_string])\n",
    "\n",
    "def find_string_from_vector(vectorized_data):\n",
    "    return \"\".join([index2string[i] for i in vectorized_data])\n",
    "\n",
    "\n",
    "vectorized_data = vectorize_string(raw_string_data)\n",
    "\n",
    "def get_batch(vectorized_data, batch_size, seq_length):\n",
    "    last_idx_of_data = vectorized_data.shape[0] - 1\n",
    "\n",
    "    starting_indices_of_samples = np.random.choice(last_idx_of_data - seq_length, batch_size)\n",
    "\n",
    "    input_batch = np.array([vectorized_data[idx : idx + seq_length] for idx in starting_indices_of_samples])\n",
    "    # The target sequences are the x_batch sequences shifted over once to the right\n",
    "    target_batch = np.array([vectorized_data[(idx + 1) : (idx + 1) + seq_length] for idx in starting_indices_of_samples])\n",
    "    x_batch = np.reshape(input_batch, [batch_size, seq_length])\n",
    "    y_batch = np.reshape(target_batch, [batch_size, seq_length])\n",
    "    return(x_batch, y_batch)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f9383526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't know too much about tenforflow's default setup of an LSTM model, \n",
    "#   so I'll use what I've seen used in the past for this sort of thing.\n",
    "def LSTM(rnn_units): \n",
    "    return tf.keras.layers.LSTM(\n",
    "      rnn_units, \n",
    "      return_sequences=True, \n",
    "      recurrent_initializer='glorot_uniform',\n",
    "      recurrent_activation='sigmoid',\n",
    "      stateful=True,\n",
    "    )\n",
    "\n",
    "def develop_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "                               tf.keras.layers.Embedding(input_dim = vocab_size,\n",
    "                                                         output_dim = embedding_dim,\n",
    "                                                         batch_input_shape = [batch_size, None]),\n",
    "                               LSTM(rnn_units = rnn_units),\n",
    "                               tf.keras.layers.Dense(units = vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f07117b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (32, None, 256)           26112     \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (32, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (32, None, 102)           104550    \n",
      "=================================================================\n",
      "Total params: 5,377,638\n",
      "Trainable params: 5,377,638\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocabulary)\n",
    "embedding_dim = embedding_dim = 2**8\n",
    "batch_size = 2**5\n",
    "rnn_units = 2**10\n",
    "model = develop_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d860d2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cross_entropy_loss(target_labels, prediction_logits):\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy(target_labels, prediction_logits, from_logits=True)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a602f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"my_ckpt\")\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.mkdir(checkpoint_dir)\n",
    "assert os.path.exists(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "178ffd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameters ###\n",
    "\n",
    "# For training optimization\n",
    "epochs = 2000\n",
    "batch_size = 2**4\n",
    "sequence_length = 100\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# For the model itself\n",
    "vocab_size = len(vocabulary)\n",
    "embedding_dim = 2**8\n",
    "rnn_units = 2**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069bf5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 1414/2000 [38:54<12:40,  1.30s/it] "
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = develop_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "# Define optimizer for training\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "# Defining training steps\n",
    "def take_training_step(model, optimizer, loss_function, x_batch, y_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction_batch_logits = model(x_batch)\n",
    "        loss = loss_function(y_batch, prediction_batch_logits)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# Train the model!\n",
    "loss_history = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    x_batch, y_batch = get_batch(vectorized_data, batch_size, seq_length = sequence_length)\n",
    "    batch_loss = take_training_step(model, optimizer, calc_cross_entropy_loss, x_batch, y_batch)\n",
    "    loss_history.append(batch_loss.numpy().mean())\n",
    "    if epoch % 100 == 0:     \n",
    "        model.save_weights(checkpoint_prefix)\n",
    "\n",
    "model.save_weights(checkpoint_prefix)\n",
    "plt.plot(loss_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ce317257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./training_checkpoints/checkpoint',\n",
       " './training_checkpoints/my_ckpt.index',\n",
       " './training_checkpoints/my_ckpt.data-00000-of-00001']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "glob(\"./training_checkpoints/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4325f52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (1, None, 256)            26112     \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (1, None, 512)            1574912   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (1, None, 102)            52326     \n",
      "=================================================================\n",
      "Total params: 1,653,350\n",
      "Trainable params: 1,653,350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = develop_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "115dbd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:15<00:00, 132.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the flowers greater, Jane Eyre.”\r\n",
      "\r\n",
      "“And did I gave you out of,—my John was to attempt, to show off, you endearch to sternles rayless. It could say, “Jane Eyre, for course with all\r\n",
      "with the end.”\r\n",
      "\r\n",
      "“Histo mine; who recivid the only, essence lay perhed?”\r\n",
      "\r\n",
      "“When, constant to beto the swell.”\r\n",
      "\r\n",
      "“Your guintage will be survensible amid, one, you enounce the present\r\n",
      "crmanting the parson; never besides, and agree is daily,”\r\n",
      "asked, he was but England; but I advanced to the boxes that as\r\n",
      "one people examining any child—it seldomy.\r\n",
      "\r\n",
      "“Bending back seen me to be mine you’ve raving, and she knew you will direct up when course your face.\r\n",
      "\r\n",
      "“I hope thaw that he answered to leave secure and love leavings: less to be use\r\n",
      "now of folds of your mind. You will be a letter band of;\r\n",
      "not the ancided love, liberty to she? But that with your aid; and Burns acknowledged\r\n",
      "resumed.\r\n",
      "\r\n",
      "“Yes—as I looks to the master’s unsideration. Afterwards he bexchadiously been rollid.\r\n",
      "\r\n",
      "But tho works: where then, come continually and wild\r\n",
      "whispering up and sentiments as here agitated, nor one which castors rishoulmed\r\n",
      "the full windows laid over rain\r\n",
      "with it at the bust when she perhaps no squest once shall remember after tracefully agane.\r\n",
      "\r\n",
      "“It shephe as drew out, well, most the feverish; in my chelicitors had dissolved to marchest whencry was high.\r\n",
      "\r\n",
      "Bessionable books remark; a Christian and abse, if their kisses\r\n",
      "over-copies friends, but one in the library’s bound and\r\n",
      "thought), as setting as much bensterves, by the very dust all—as she recommenced with the pideless fuxed for Mr. Rochester. And\r\n",
      "she thought room? as\r\n",
      "and threw for ake, like her with whom nothing, will be suddenly drived mp\r\n",
      "the anguight powered stores, which two time. It hastened last visitous round me some more\r\n",
      "of the ths whoild dress you that I had then, it sewed him for\r\n",
      "my eye come up and thought, and then n, was risks, and it was just swells\r\n",
      "as I endeavouring, and the countenance I had made my musual,\r\n",
      "both a bitter \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_string_data(model, start_character, length = 100):\n",
    "    beginning_input = string2index[start_character]\n",
    "    beginning_input = tf.expand_dims([beginning_input], 0)\n",
    "\n",
    "    model.reset_states()\n",
    "\n",
    "    generated_char_list = []\n",
    "    for i in tqdm(range(length)):\n",
    "        predictions = model(beginning_input)\n",
    "\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples = 1)[-1,0].numpy()\n",
    "        generated_char_list.append(index2string[predicted_id])\n",
    "\n",
    "        beginning_input = tf.expand_dims([predicted_id], 0)\n",
    "    return start_character + \"\".join(generated_char_list)\n",
    "\n",
    "print(generate_string_data(model = model, start_character = \" \", length = 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa189a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
